{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c808ae44-1886-470d-aea2-2ac40b9b1015",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import random\n",
    "import os\n",
    "import shutil"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b423cae-a346-43a3-b12b-f017d828056a",
   "metadata": {},
   "source": [
    "# VinDr-CXR Preparation\n",
    "\n",
    "In this notebook, I bring the [kaggle version of the VinDr-CXR dataset](https://www.kaggle.com/c/vinbigdata-chest-xray-abnormalities-detection) into the same format as the [official dataset from PhysioNet](https://physionet.org/content/vindr-cxr/1.0.0/). \n",
    "\n",
    "Download and unzip the data and enter its path into `data_path`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0646a750-d757-43e4-858d-6d365fdcd61f",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = \"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "419dbb8c-3844-428b-944d-be10814676a3",
   "metadata": {},
   "source": [
    "Like in the *Many Tasks Make Light Work* paper, I now create a training set consisting of 4000 healthy scans and a test set consisting of 1000 healthy and 1000 unhealthy scans.\n",
    "\n",
    "First, let's have a look at the dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56cc1381-5001-45fe-a151-f60f67ede7d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(data_path + \"/train.csv\").sort_values(by=\"image_id\")\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3724982c-3916-4d75-93fd-32fe6344cdc0",
   "metadata": {},
   "source": [
    "The possible labels are the following:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e6d271c8-6469-4a84-90e9-8e2a197c5934",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_dict = {\n",
    "    0: \"Aortic enlargement\",\n",
    "    1: \"Atelectasis\",\n",
    "    2: \"Calcification\",\n",
    "    3: \"Cardiomegaly\",\n",
    "    4: \"Consolidation\",\n",
    "    5: \"ILD\",\n",
    "    6: \"Infiltration\",\n",
    "    7: \"Lung Opacity\",\n",
    "    8: \"Nodule/Mass\",\n",
    "    9: \"Other lesion\",\n",
    "    10: \"Pleural effusion\",\n",
    "    11: \"Pleural thickening\",\n",
    "    12: \"Pneumothorax\",\n",
    "    13: \"Pulmonary fibrosis\",\n",
    "    14: \"No finding\"\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "843276be",
   "metadata": {},
   "source": [
    "To create the training set, I extract the rows from the dataframe which belong to the scans that were labeled as healthy (`\"No finding\"`) by all three radiologists and store them in the dataframe `df_healthy`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba4a4461-25e3-4f4c-a2d5-5506cb503c94",
   "metadata": {},
   "outputs": [],
   "source": [
    "ids_three_occurences = df[\"image_id\"].value_counts()[lambda x: x == 3].index\n",
    "df_healthy = df[df[\"image_id\"].isin(ids_three_occurences)]\n",
    "df_healthy = df_healthy[df_healthy[\"class_name\"] == \"No finding\"]\n",
    "df_healthy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a1f64a7",
   "metadata": {},
   "source": [
    "Next, I extract the rows belonging to the scans which were not labeled as healthy by any of the three radiologists into the dataframe `df_unhealthy`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d8a096cc-95fb-4930-ab5b-e02c43fa7804",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_unhealthy = df.groupby(\"image_id\").filter(lambda group: not (group[\"class_name\"] == \"No finding\").any()) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acb9d1e5",
   "metadata": {},
   "source": [
    "Now, 4000 healthy scans and further 1000 healthy and 1000 unhealthy scans are chosen randomly to form the training and the test set. The `image_id`s of these scans are stored in the dictionary `train_test_ids`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "47d3ca4f-e397-4fd3-b9a5-f674246351d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "random.seed(2005)\n",
    " \n",
    "train_test_ids = {\"train\": [], \"test\": []}\n",
    "\n",
    "image_ids_healthy = df_healthy[\"image_id\"].unique().tolist() \n",
    "image_ids_healthy_5000 = random.sample(image_ids_healthy, 5000)\n",
    "image_ids_unhealthy = df_unhealthy[\"image_id\"].unique().tolist()\n",
    "image_ids_unhealthy_1000 = random.sample(image_ids_unhealthy, 1000)\n",
    "\n",
    "train_test_ids[\"train\"].extend(image_ids_healthy_5000[:4000])\n",
    "train_test_ids[\"test\"].extend(image_ids_healthy_5000[4000:])\n",
    "train_test_ids[\"test\"].extend(image_ids_unhealthy_1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ee19179",
   "metadata": {},
   "source": [
    "The annotations and labels of the training data are stored in the files `annotations_train.csv` and `image_labels_train.csv` respectively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "971ba77e-3d6e-4f17-ae11-e28b898a8af2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_annotations_train = df[df[\"image_id\"].isin(train_test_ids[\"train\"])]\n",
    "\n",
    "df_annotations_train.to_csv(\"annotations_train.csv\", index=False)\n",
    "\n",
    "df_image_labels_train = df_annotations_train.loc[:, [\"image_id\", \"rad_id\"]]\n",
    "for label in labels_dict.values():\n",
    "    df_image_labels_train[label] = 0\n",
    "df_image_labels_train[\"No finding\"] = 1\n",
    "\n",
    "df_image_labels_train.to_csv(\"image_labels_train.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cd7f919",
   "metadata": {},
   "source": [
    "The annotations of the original test data are a consensus of various radiologists and are therefore not associated with an individual radiologist. As the kaggle dataset does not contain these consensus annotations, I simply only keep one randomly chosen row per (`\"image_id\"`, `\"class_name\"`) pair and remove the column containing the ID `rad_id` of the radiologist."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c8347ff7-543b-4015-89fc-63e483c9aecf",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_annotations_test = df[df[\"image_id\"].isin(train_test_ids[\"test\"])]\n",
    "df_annotations_test = df_annotations_test.drop_duplicates(subset=[\"image_id\", \"class_name\"], keep=\"first\")\n",
    "del df_annotations_test[\"rad_id\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8308534c",
   "metadata": {},
   "source": [
    "The annotations and labels of the test data are stored in the files `annotations_test.csv` and `image_labels_test.csv` respectively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1534de69-a82b-45c0-b4ca-67e55ba60e7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_annotations_test.to_csv(\"annotations_test.csv\", index=False)\n",
    "\n",
    "df_image_labels_test = pd.DataFrame(train_test_ids[\"test\"], columns = [\"image_id\"])\n",
    "for label in labels_dict.values():\n",
    "    df_image_labels_test[label] = 0\n",
    "df_image_labels_test[\"No finding\"] = 0\n",
    "\n",
    "for idx, row in df_annotations_test.iterrows():\n",
    "    image_id_idx = df_image_labels_test.loc[df_image_labels_test[\"image_id\"] == row[\"image_id\"]].index[0]\n",
    "    df_image_labels_test.loc[image_id_idx, row[\"class_name\"]] = 1 \n",
    "\n",
    "df_image_labels_test.to_csv(\"image_labels_test.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "c11574c9-4be1-45f4-a75a-d51c3a949fe2",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.makedirs(data_path + \"/train\", exist_ok=True)\n",
    "os.makedirs(data_path + \"/test\", exist_ok=True)\n",
    "os.makedirs(data_path + \"/annotations\", exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8d482d3",
   "metadata": {},
   "source": [
    "Now, I remove the created CSV files to `<data_path>/annotations`, the scans forming the training and the test set to `<data_path>/train` and `<data_path>/test` and delete the remaining files at `data_path`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37338531-5c13-4a81-92ec-43771d14e6a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "for file_name in [\"annotations_test.csv\", \"annotations_train.csv\", \"image_labels_test.csv\", \"image_labels_train.csv\"]:\n",
    "    shutil.move(file_name, data_path + \"/annotations/\" + file_name)\n",
    "    \n",
    "for mode in [\"train\", \"test\"]:\n",
    "    for file_name in train_test_ids[mode]:\n",
    "        shutil.move(data_path + \"/\" + file_name + \".dicom\",\n",
    "                    data_path + \"/\" + mode + \"/\" + file_name + \".dicom\")\n",
    "        \n",
    "for entry in os.listdir(data_path):\n",
    "    if os.path.isfile(data_path + \"/\" + entry):\n",
    "        os.remove(data_path + \"/\" + entry)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (multitask_method_env)",
   "language": "python",
   "name": "multitask_method_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
